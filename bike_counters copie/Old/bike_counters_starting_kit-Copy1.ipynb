{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18cc7ae5-7438-402e-8196-bb931e3e6c6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RAMP on predicting cyclist traffic in Paris\n",
    "\n",
    "Authors: *Roman Yurchak (Symerio)*; also partially inspired by the air_passengers starting kit.\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The dataset was collected with cyclist counters installed by Paris city council in multiple locations. It contains hourly information about cyclist traffic, as well as the following features,\n",
    " - counter name\n",
    " - counter site name\n",
    " - date\n",
    " - counter installation date\n",
    " - latitude and longitude\n",
    " \n",
    "Available features are quite scarce. However, **we can also use any external data that can help us to predict the target variable.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0a4cf3f-8907-443b-adff-6fe13ef29d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5117809-38b8-44f8-8b09-a99989ef1d50",
   "metadata": {},
   "source": [
    "# Loading the data with pandas\n",
    "\n",
    "First, download the data files,\n",
    " - [train.parquet](https://github.com/rth/bike_counters/releases/download/v0.1.0/train.parquet)\n",
    " - [test.parquet](https://github.com/rth/bike_counters/releases/download/v0.1.0/test.parquet)\n",
    "\n",
    "and put them to into the data folder.\n",
    "\n",
    "\n",
    "Data is stored in [Parquet format](https://parquet.apache.org/), an efficient columnar data format. We can load the train set with pandas,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61c60288-e71b-46ae-9eb3-d916d2abc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(Path(\"data\") / \"train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "745fedf9-07e4-4020-b3b5-484b721675ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter_id</th>\n",
       "      <th>counter_name</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_name</th>\n",
       "      <th>bike_count</th>\n",
       "      <th>date</th>\n",
       "      <th>counter_installation_date</th>\n",
       "      <th>counter_technical_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>log_bike_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48321</th>\n",
       "      <td>100007049-102007049</td>\n",
       "      <td>28 boulevard Diderot E-O</td>\n",
       "      <td>100007049</td>\n",
       "      <td>28 boulevard Diderot</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-09-01 02:00:00</td>\n",
       "      <td>2013-01-18</td>\n",
       "      <td>Y2H15027244</td>\n",
       "      <td>48.846028</td>\n",
       "      <td>2.375429</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48324</th>\n",
       "      <td>100007049-102007049</td>\n",
       "      <td>28 boulevard Diderot E-O</td>\n",
       "      <td>100007049</td>\n",
       "      <td>28 boulevard Diderot</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-09-01 03:00:00</td>\n",
       "      <td>2013-01-18</td>\n",
       "      <td>Y2H15027244</td>\n",
       "      <td>48.846028</td>\n",
       "      <td>2.375429</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48327</th>\n",
       "      <td>100007049-102007049</td>\n",
       "      <td>28 boulevard Diderot E-O</td>\n",
       "      <td>100007049</td>\n",
       "      <td>28 boulevard Diderot</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-09-01 04:00:00</td>\n",
       "      <td>2013-01-18</td>\n",
       "      <td>Y2H15027244</td>\n",
       "      <td>48.846028</td>\n",
       "      <td>2.375429</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48330</th>\n",
       "      <td>100007049-102007049</td>\n",
       "      <td>28 boulevard Diderot E-O</td>\n",
       "      <td>100007049</td>\n",
       "      <td>28 boulevard Diderot</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-09-01 15:00:00</td>\n",
       "      <td>2013-01-18</td>\n",
       "      <td>Y2H15027244</td>\n",
       "      <td>48.846028</td>\n",
       "      <td>2.375429</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48333</th>\n",
       "      <td>100007049-102007049</td>\n",
       "      <td>28 boulevard Diderot E-O</td>\n",
       "      <td>100007049</td>\n",
       "      <td>28 boulevard Diderot</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2020-09-01 18:00:00</td>\n",
       "      <td>2013-01-18</td>\n",
       "      <td>Y2H15027244</td>\n",
       "      <td>48.846028</td>\n",
       "      <td>2.375429</td>\n",
       "      <td>2.302585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                counter_id              counter_name    site_id  \\\n",
       "48321  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
       "48324  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
       "48327  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
       "48330  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
       "48333  100007049-102007049  28 boulevard Diderot E-O  100007049   \n",
       "\n",
       "                  site_name  bike_count                date  \\\n",
       "48321  28 boulevard Diderot         0.0 2020-09-01 02:00:00   \n",
       "48324  28 boulevard Diderot         1.0 2020-09-01 03:00:00   \n",
       "48327  28 boulevard Diderot         0.0 2020-09-01 04:00:00   \n",
       "48330  28 boulevard Diderot         4.0 2020-09-01 15:00:00   \n",
       "48333  28 boulevard Diderot         9.0 2020-09-01 18:00:00   \n",
       "\n",
       "      counter_installation_date counter_technical_id   latitude  longitude  \\\n",
       "48321                2013-01-18          Y2H15027244  48.846028   2.375429   \n",
       "48324                2013-01-18          Y2H15027244  48.846028   2.375429   \n",
       "48327                2013-01-18          Y2H15027244  48.846028   2.375429   \n",
       "48330                2013-01-18          Y2H15027244  48.846028   2.375429   \n",
       "48333                2013-01-18          Y2H15027244  48.846028   2.375429   \n",
       "\n",
       "       log_bike_count  \n",
       "48321        0.000000  \n",
       "48324        0.693147  \n",
       "48327        0.000000  \n",
       "48330        1.609438  \n",
       "48333        2.302585  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e488c773-761d-48fb-9d26-3c4b55e3f2b7",
   "metadata": {},
   "source": [
    "We can check general information about different columns,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2649650-6e2a-4641-8221-266c829aec37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 455163 entries, 48321 to 928462\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   counter_id                 455163 non-null  category      \n",
      " 1   counter_name               455163 non-null  category      \n",
      " 2   site_id                    455163 non-null  int64         \n",
      " 3   site_name                  455163 non-null  category      \n",
      " 4   bike_count                 455163 non-null  float64       \n",
      " 5   date                       455163 non-null  datetime64[ns]\n",
      " 6   counter_installation_date  455163 non-null  datetime64[ns]\n",
      " 7   counter_technical_id       455163 non-null  category      \n",
      " 8   latitude                   455163 non-null  float64       \n",
      " 9   longitude                  455163 non-null  float64       \n",
      " 10  log_bike_count             455163 non-null  float64       \n",
      "dtypes: category(4), datetime64[ns](2), float64(4), int64(1)\n",
      "memory usage: 29.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586ebce3-c013-4c5e-ab78-03a8d8d86d7e",
   "metadata": {},
   "source": [
    "and in particular the number of unique entries in each column,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a88d812-daf9-451d-baa6-67bf735ae368",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7504b6-d301-4d37-aa55-4d73b0dcedbd",
   "metadata": {},
   "source": [
    "We have a 30 counting sites where sometimes multiple counters are installed per location.  Let's look at the most frequented stations,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6286212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['site_name', 'counter_name'])['bike_count'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1c75a9-1976-4a97-bf11-76d0026b591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby([\"site_name\", \"counter_name\"])[\"bike_count\"].sum().sort_values(\n",
    "    ascending=False\n",
    ").head(10).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1dc688-2649-4f7f-9326-157b08ea4bae",
   "metadata": {},
   "source": [
    "# Visualizing the data\n",
    "\n",
    "\n",
    "Let's visualize the data, starting from the spatial distribution of counters on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1fe386-fb15-4d60-b9f8-8b4b2bc175b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "m = folium.Map(location=data[[\"latitude\", \"longitude\"]].mean(axis=0), zoom_start=13)\n",
    "\n",
    "for _, row in (\n",
    "    data[[\"counter_name\", \"latitude\", \"longitude\"]]\n",
    "    .drop_duplicates(\"counter_name\")\n",
    "    .iterrows()\n",
    "):\n",
    "    folium.Marker(\n",
    "        row[[\"latitude\", \"longitude\"]].values.tolist(), popup=row[\"counter_name\"]\n",
    "    ).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a58f27-b2c3-4eee-8991-b206471eb723",
   "metadata": {},
   "source": [
    "Note that in this RAMP problem we consider only the 30 most frequented counting sites, to limit data size.\n",
    "\n",
    "\n",
    "Next we will look into the temporal distribution of the most frequented bike counter. If we plot it directly we will not see much because there are half a million data points,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe0c1a0-e661-4dd9-bf14-be1ac5a1a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data[\"counter_name\"] == \"Totem 73 boulevard de Sébastopol S-N\"\n",
    "\n",
    "data[mask].plot(x=\"date\", y=\"bike_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6782d258-580c-4db4-9b96-fa1e16d89b2f",
   "metadata": {},
   "source": [
    "Instead we aggregate the data, for instance, by week to have a clearer overall picture,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349fbd40-c57e-40cc-bd99-608d9e2e89ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data[\"counter_name\"] == \"Totem 73 boulevard de Sébastopol S-N\"\n",
    "\n",
    "data[mask].groupby(pd.Grouper(freq=\"1w\", key=\"date\"))[[\"bike_count\"]].sum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c262f5c5-3a54-4017-a99b-fed24eee385f",
   "metadata": {},
   "source": [
    "While at the same time, we can zoom on a week in particular for a more short-term visualization,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b5840-53ba-43ca-8966-f594975696c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "mask = (\n",
    "    (data[\"counter_name\"] == \"Totem 73 boulevard de Sébastopol S-N\")\n",
    "    & (data[\"date\"] > pd.to_datetime(\"2021/03/01\"))\n",
    "    & (data[\"date\"] < pd.to_datetime(\"2021/03/08\"))\n",
    ")\n",
    "\n",
    "data[mask].plot(x=\"date\", y=\"bike_count\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca56052b-51f7-4c67-b135-2cc14698448f",
   "metadata": {},
   "source": [
    "The hourly pattern has a clear variation between work days and weekends (7 and 8 March 2021).\n",
    "\n",
    "If we look at the distribution of the target variable it skewed and non normal, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99893b87-cc1c-4c3e-b0cc-2069eb0e6874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "ax = sns.histplot(data, x=\"bike_count\", kde=True, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0055ae-ea52-4198-bc31-5089e73aaf9e",
   "metadata": {},
   "source": [
    "Least square loss would not be appropriate to model it since it is designed for normal error distributions. One way to precede would be to transform the variable with a logarithmic transformation,\n",
    "```py\n",
    "data['log_bike_count'] = np.log(1 + data['bike_count'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6414fb09-93e7-431a-ac04-237ca8ccea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(data, x=\"log_bike_count\", kde=True, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ce873c-aa3d-40a8-9f07-ef1692df281d",
   "metadata": {},
   "source": [
    "which has a more pronounced central mode, but is still non symmetric. In the following, **we use `log_bike_count` as the target variable** as otherwise `bike_count` ranges over 3 orders of magnitude and least square loss would be dominated by the few large values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51fc59f-e77f-4c82-bfe8-35a93ef2db09",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "\n",
    "To account for the temporal aspects of the data, we cannot input the `date` field directly into the model. Instead we extract the features on different time-scales from the `date` field, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d9bfd-7852-4206-b16f-e09e7c83d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encode_dates(X):\n",
    "    X = X.copy()  # modify a copy of X\n",
    "    # Encode the date information from the DateOfDeparture columns\n",
    "    X.loc[:, \"year\"] = X[\"date\"].dt.year\n",
    "    X.loc[:, \"month\"] = X[\"date\"].dt.month\n",
    "    X.loc[:, \"day\"] = X[\"date\"].dt.day\n",
    "    X.loc[:, \"weekday\"] = X[\"date\"].dt.weekday\n",
    "    X.loc[:, \"hour\"] = X[\"date\"].dt.hour\n",
    "\n",
    "    # Finally we can drop the original columns from the dataframe\n",
    "    return X.drop(columns=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a9c16-69fb-4d05-aa77-5ef1bc28fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"date\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd6cfea-6fc8-4707-a0c9-404b62a7833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_encode_dates(data[[\"date\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eb15a9-421b-4f2a-a913-26df51449092",
   "metadata": {},
   "source": [
    "To use this function with scikit-learn estimators we wrap it with [FunctionTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4676f76-1bdb-4fdd-94b3-061a9a7c691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "date_encoder = FunctionTransformer(_encode_dates, validate=False)\n",
    "date_encoder.fit_transform(data[[\"date\"]]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c85678-2403-4a31-90ae-ac68f9565859",
   "metadata": {},
   "source": [
    "Since it is unlikely that, for instance, that `hour` is linearly correlated with the target variable, we would need to additionally encode categorical features for linear models. This is classically done with [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), though other encoding strategies exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e5f3cd-e177-4b73-8058-1472a46bb34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "enc.fit_transform(_encode_dates(data[[\"date\"]])[[\"hour\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5feb47c-c05f-442b-8009-4b7272bdf84f",
   "metadata": {},
   "source": [
    "## Linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb001e-3446-492c-b887-6ed485448495",
   "metadata": {},
   "source": [
    "Let's now construct our first linear model with [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html). We use a few helper functions defined in `problem.py` of the starting kit to load the public train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809fa5fa-099f-4b98-b47c-98f4e11ea0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import problem\n",
    "\n",
    "X_train, y_train = problem.get_train_data()\n",
    "X_test, y_test = problem.get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e579d41-9f7a-4b50-b07d-31866168a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ea2f21-1d7b-48d0-87ce-e55440a99360",
   "metadata": {},
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c396114-de58-40b4-bfd3-10c0c7f4f83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937ebcf8-8769-46b4-93f8-d54a30194f87",
   "metadata": {},
   "source": [
    "Where `y` contains the `log_bike_count` variable. \n",
    "\n",
    "The test set is in the future as compared to the train set,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252bf7ea-2def-46e1-b4fd-583c0e2c3f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f'Train: n_samples={X_train.shape[0]},  {X_train[\"date\"].min()} to {X_train[\"date\"].max()}'\n",
    ")\n",
    "print(\n",
    "    f'Test: n_samples={X_test.shape[0]},  {X_test[\"date\"].min()} to {X_test[\"date\"].max()}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d1c151-da75-4dae-bbe6-07bf06e2b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_encode_dates(X_train[[\"date\"]]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e7450-5529-47e5-a311-c78e364048ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "date_encoder = FunctionTransformer(_encode_dates)\n",
    "date_cols = _encode_dates(X_train[[\"date\"]]).columns.tolist()\n",
    "\n",
    "categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "categorical_cols = [\"counter_name\", \"site_name\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"date\", OneHotEncoder(handle_unknown=\"ignore\"), date_cols),\n",
    "        (\"cat\", categorical_encoder, categorical_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "regressor = Ridge()\n",
    "\n",
    "pipe = make_pipeline(date_encoder, preprocessor, regressor)\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772e16fe-50fd-4229-af39-a6ebefad0a1e",
   "metadata": {},
   "source": [
    "We then evaluate this model with the RMSE metric,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4d803c-80ea-4423-af83-5666c799838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\n",
    "    f\"Train set, RMSE={mean_squared_error(y_train, pipe.predict(X_train), squared=False):.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Test set, RMSE={mean_squared_error(y_test, pipe.predict(X_test), squared=False):.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2298cbed-ff41-49f4-9e51-6925410fc083",
   "metadata": {},
   "source": [
    "The model doesn't have enough capacity to generalize on the train set, since we have lots of data with relatively few parameters. However it happened to work somewhat better on the test set. We can compare these results with the baseline predicting the mean value,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20e09d6-cbe8-4911-bfe1-ef5e939cacb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline mean prediction.\")\n",
    "print(\n",
    "    f\"Train set, RMSE={mean_squared_error(y_train, np.full(y_train.shape, y_train.mean()), squared=False):.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Test set, RMSE={mean_squared_error(y_test, np.full(y_test.shape, y_test.mean()), squared=False):.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c753fe34-a94b-4d18-9497-e516c1ccc4e2",
   "metadata": {},
   "source": [
    "which illustrates that we are performing better than the baseline.\n",
    "\n",
    "Let's visualize the predictions for one of the stations,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2509f6-7cba-4671-8363-d4abda33ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (\n",
    "    (X_test[\"counter_name\"] == \"Totem 73 boulevard de Sébastopol S-N\")\n",
    "    & (X_test[\"date\"] > pd.to_datetime(\"2021/09/01\"))\n",
    "    & (X_test[\"date\"] < pd.to_datetime(\"2021/09/08\"))\n",
    ")\n",
    "\n",
    "df_viz = X_test.loc[mask].copy()\n",
    "df_viz[\"bike_count\"] = np.exp(y_test[mask.values]) - 1\n",
    "df_viz[\"bike_count (predicted)\"] = np.exp(pipe.predict(X_test[mask])) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fab3196-90bd-4918-a509-01cd38b1adfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "df_viz.plot(x=\"date\", y=\"bike_count\", ax=ax)\n",
    "df_viz.plot(x=\"date\", y=\"bike_count (predicted)\", ax=ax, ls=\"--\")\n",
    "ax.set_title(\"Predictions with Ridge\")\n",
    "ax.set_ylabel(\"bike_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187d342e-ba15-4741-a457-d4ae31d07c9a",
   "metadata": {},
   "source": [
    "So we start to see the daily trend, and some of the week day differences are accounted for, however we still miss the details and the spikes in the evening are under-estimated.\n",
    "\n",
    "A useful way to visualize the error is to plot `y_pred` as a function of `y_true`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef6c8cd-56ce-4294-8d98-da217262aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "df_viz = pd.DataFrame({\"y_true\": y_test, \"y_pred\": pipe.predict(X_test)}).sample(\n",
    "    10000, random_state=0\n",
    ")\n",
    "\n",
    "df_viz.plot.scatter(x=\"y_true\", y=\"y_pred\", s=8, alpha=0.1, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d82e36-4033-4d96-a501-d2f56578c894",
   "metadata": {},
   "source": [
    "It is recommended to use cross-validation for hyper-parameter tuning with [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) or more reliable model evaluation with [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score). In this case, because we want the test data to always be in the future as compared to the train data, we can use [TimeSeriesSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html),\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/Q37Bn.png\" />\n",
    "\n",
    "The disadvantage, is that we can either have the training set size be different for each fold which is not ideal for hyper-parameter tuning (current figure), or have constant sized small training set which is also not ideal given the data periodicity. This explains that generally we will have worse cross-validation scores than test scores, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4781077b-9da4-4db4-af9a-c130cb9b2182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "\n",
    "cv = TimeSeriesSplit(n_splits=6)\n",
    "\n",
    "# When using a scorer in scikit-learn it always needs to be better when smaller, hence the minus sign.\n",
    "scores = cross_val_score(\n",
    "    pipe, X_train, y_train, cv=cv, scoring=\"neg_root_mean_squared_error\"\n",
    ")\n",
    "print(\"RMSE: \", scores)\n",
    "print(f\"RMSE (all folds): {-scores.mean():.3} ± {(-scores).std():.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74db817",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d24838c-eb08-45c7-a49e-e85d71418cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd17a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()  # Apply the default theme of seaborn\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 4)  # Set the figure size for all plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34e2786",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b10e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c627e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb448449",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9f51aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in data.select_dtypes(include=[\"object\"]).columns:\n",
    "    print(\n",
    "        f\"\\nFor the {feature} feature, we have {data[feature].nunique()} categories which are:\"\n",
    "        f\"\\n\\t{sorted(list(data[feature].unique()))}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11d0c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby([\"site_name\", \"counter_name\"])[\"bike_count\"].sum().sort_values(\n",
    "    ascending=False\n",
    ").head(10).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b691ae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby([\"longitude\", \"latitude\"])[\"bike_count\"].sum().sort_values(\n",
    "    ascending=False\n",
    ").head(10).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e036f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"longitude\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a487eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"latitude\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"bike_count\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afdeef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(data[\"bike_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a7b4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038080f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6edb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy.drop(\"counter_name\", axis=1, inplace=True)\n",
    "data_copy.drop(\"site_name\", axis=1, inplace=True)\n",
    "data_copy.drop(\"counter_technical_id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c81564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy.drop(\"bike_count\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a50fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c94c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y\n",
    "from sklearn.utils.validation import check_array\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.utils.multiclass import check_classification_targets\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import fmin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import tree\n",
    "import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fdc82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[\"Hour\"] = data_copy[\"date\"].dt.hour\n",
    "data_copy[\"Day\"] = data_copy[\"date\"].dt.day\n",
    "data_copy[\"Week\"] = data_copy[\"date\"].dt.week\n",
    "data_copy[\"Month\"] = data_copy[\"date\"].dt.month\n",
    "data_copy[\"Year\"] = data_copy[\"date\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618f47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ddbb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee983679",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy.drop(\"date\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09bda84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a17fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy.drop(\"bike_count\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1074e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb6dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26cf68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e93650",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_copy.drop(\"log_bike_count\", axis=1)\n",
    "y = data_copy[\"log_bike_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3942d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size = .75)\n",
    "print(\n",
    "    f\"The training dataset contains {X_train.shape[0]} samples and \"\n",
    "    f\"{X_train.shape[1]} features\"\n",
    ")\n",
    "print(\n",
    "    f\"The testing dataset contains {X_test.shape[0]} samples and \"\n",
    "    f\"{X_test.shape[1]} features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6604030",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.arange(1, 30, dtype='int64')\n",
    "RMSE_train = []\n",
    "RMSE_test = []\n",
    "\n",
    "for x in L:\n",
    "    # RMSE for depth 0 <= x < 10\n",
    "    reg = DecisionTreeRegressor(max_depth=x, random_state=42)\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    model_train = reg.predict(X_train)\n",
    "    model_test = reg.predict(X_test)\n",
    "    RMSE_train.append(mean_squared_error(y_train, model_train, \n",
    "                                         squared=False))\n",
    "    RMSE_test.append(mean_squared_error(y_test, model_test, \n",
    "                                        squared=False))\n",
    "\n",
    "figure(figsize=(14, 8), dpi=180)\n",
    "plt.plot(L, RMSE_train, c='b', label='Train error')\n",
    "plt.plot(L, RMSE_test, c='y', label='Test error')\n",
    "plt.xlabel('Max depth')\n",
    "plt.ylabel('Test and train RMSE')\n",
    "plt.title('Test and train RMSE as a function of max depth')\n",
    "plt.legend()\n",
    "print(\"The max depth is\", np.argmin(RMSE_test) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be20835",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(RMSE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10808052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81856d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56065441",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8eb34f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
